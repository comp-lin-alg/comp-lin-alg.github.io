<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Linear algebra preliminaries &#8212; Computational linear algebra course 2023.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/fenics.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/proof.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. QR factorisation" href="L2_QR_factorisation.html" />
    <link rel="prev" title="1. Getting ready for computational exercises" href="L0_setup.html" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

<link rel="stylesheet" href="_static/featured.css">


<link rel="shortcut icon" href="_static/icon.ico" />


  </head><body>
<div class="wrapper">
  <a href="index.html"><img src="_static/banner.png" width="900px" alt="Project Banner" /></a>
  <div id="access">
    <div class="menu">
      <ul>
          <li class="page_item"><a href="https://github.com/Computational-Linear-Algebra-Course/computational-linear-algebra-course" title="GitHub">GitHub</a></li>
      </ul>
    </div><!-- .menu -->
  </div><!-- #access -->
</div><!-- #wrapper -->


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="linear-algebra-preliminaries">
<h1><span class="section-number">2. </span>Linear algebra preliminaries<a class="headerlink" href="#linear-algebra-preliminaries" title="Permalink to this heading">¶</a></h1>
<p>In this preliminary section, we revise a few key linear algebra
concepts that will be used in the rest of the course, emphasising
the column space of matrices. We will quote some standard results
that should be found in an undergraduate linear algebra course.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Before you attempt any exercises, you need to make sure that you
have everything you need set up on your computer. See the checklist
in <a class="reference internal" href="L0_setup.html#comp-exercises"><span class="std std-ref">the previous section</span></a>.</p>
</div>
<section id="matrices-vectors-and-matrix-vector-multiplication">
<h2><span class="section-number">2.1. </span>Matrices, vectors and matrix-vector multiplication<a class="headerlink" href="#matrices-vectors-and-matrix-vector-multiplication" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450145459" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>We will consider the multiplication of a vector</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}x = \begin{pmatrix} x_1 \\
x_2 \\
\vdots \\
x_n \\
\end{pmatrix}, \quad x_i \in \mathbb{C}, \, i=1,2,\ldots,n,
\mbox{ i.e. } x \in \mathbb{C}^n,\end{split}\]</div>
</div></blockquote>
<p>by a matrix</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}A = \begin{pmatrix}
a_{11} &amp; a_{12} &amp; \ldots &amp; a_{1n} \\
a_{21} &amp; a_{22} &amp; \ldots &amp; a_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; a_{m2} &amp; \ldots &amp; a_{mn} \\
\end{pmatrix},\end{split}\]</div>
</div></blockquote>
<p>i.e. <span class="math notranslate nohighlight">\(A\in \mathbb{C}^{m\times n}\)</span>. <span class="math notranslate nohighlight">\(A\)</span> has <span class="math notranslate nohighlight">\(m\)</span> rows and <span class="math notranslate nohighlight">\(n\)</span> columns
so that the product</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[b = Ax\]</div>
</div></blockquote>
<p>produces <span class="math notranslate nohighlight">\(b \in \mathbb{C}^m\)</span>, defined by</p>
<blockquote>
<div><div class="math notranslate nohighlight" id="equation-matvec">
<span class="eqno">(2.1)<a class="headerlink" href="#equation-matvec" title="Permalink to this equation">¶</a></span>\[b_i = \sum_{j=1}^n a_{ij}x_j, \, i=1,2,\ldots,m.\]</div>
</div></blockquote>
<p>In this course it is important to
consider the general case where <span class="math notranslate nohighlight">\(m \neq n\)</span>, which has many applications
in data analysis, curve fitting etc. We will usually state generalities
in this course for vectors over the field <span class="math notranslate nohighlight">\(\mathbb{C}\)</span>, noting where things
specialise to <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.</p>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450156255" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>We can quickly check that the map <span class="math notranslate nohighlight">\(x \to Ax\)</span> given by matrix
multiplication is a linear map from <span class="math notranslate nohighlight">\(\mathbb{C}^n \to \mathbb{C}^m\)</span>, since
it is straightforward to check from the definition that</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[A(\alpha x + y) = \alpha Ax + Ay,\]</div>
</div></blockquote>
<p>for all <span class="math notranslate nohighlight">\(x,y \in \mathbb{C}^n\)</span> and <span class="math notranslate nohighlight">\(\alpha\in \mathbb{C}\)</span>. (Exercise:
show this for yourself.)</p>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450157385" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>It is very useful to interpret matrix-vector multiplication as a linear
combination of the columns of <span class="math notranslate nohighlight">\(A\)</span> with coefficients taken from the entries
of <span class="math notranslate nohighlight">\(x\)</span>. If we write <span class="math notranslate nohighlight">\(A\)</span> in terms of the columns,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}A = \begin{pmatrix}
a_1 &amp; a_2 &amp; \ldots &amp; a_n \\
\end{pmatrix},\end{split}\]</div>
</div></blockquote>
<p>where</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[a_i \in \mathbb{C}^m, \, i=1,2,\ldots,n,\]</div>
</div></blockquote>
<p>then</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[b = \sum_{j=1}^n x_j a_j,\]</div>
</div></blockquote>
<p>i.e. a linear combination of the columns of <span class="math notranslate nohighlight">\(A\)</span> as described above.</p>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450161699" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>We can extend this idea to matrix-matrix multiplication. Taking
<span class="math notranslate nohighlight">\(A\in \mathbb{C}^{m\times l}\)</span>, <span class="math notranslate nohighlight">\(C\in \mathbb{C}^{l\times n}\)</span>,
<span class="math notranslate nohighlight">\(B\in \mathbb{C}^{m\times n}\)</span>, with <span class="math notranslate nohighlight">\(B=AC\)</span>, then the components of
<span class="math notranslate nohighlight">\(B\)</span> are given by</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[b_{ij} = \sum_{k=1}^l a_{ik}c_{kj}, \quad 1\leq i \leq m, \,
1\leq j \leq n.\]</div>
</div></blockquote>
<p>Writing <span class="math notranslate nohighlight">\(b_j \in \mathbb{C}^m\)</span> as the jth column of <span class="math notranslate nohighlight">\(B\)</span>, for <span class="math notranslate nohighlight">\(1\leq j \leq n\)</span>,
and <span class="math notranslate nohighlight">\(c_j\)</span> as the jth column of <span class="math notranslate nohighlight">\(C\)</span>,
we see that</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[b_j = Ac_j.\]</div>
</div></blockquote>
<p>This means that the jth column of <span class="math notranslate nohighlight">\(B\)</span> is the matrix-vector product of
<span class="math notranslate nohighlight">\(A\)</span> with the jth column of <span class="math notranslate nohighlight">\(C\)</span>. This kind of “column thinking” is very
useful in understanding computational linear algebra algorithms.</p>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450162431" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>An important example is the outer product of two vectors, <span class="math notranslate nohighlight">\(u \in
\mathbb{C}^m\)</span> and <span class="math notranslate nohighlight">\(v \in \mathbb{C}^n\)</span>. Here it is useful to see these
vectors as matrices with one column, i.e. <span class="math notranslate nohighlight">\(u \in \mathbb{C}^{m\times
1}\)</span> and <span class="math notranslate nohighlight">\(v \in \mathbb{C}^{n\times 1}\)</span>. The outer product is <span class="math notranslate nohighlight">\(u v^T
\in \mathbb{C}^{m\times n}\)</span>. The columns of <span class="math notranslate nohighlight">\(v^T\)</span> are just single numbers
(i.e. vectors of length 1), so viewing this as a matrix multiplication
we see</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[uv^T = \begin{pmatrix}
uv_1 &amp; uv_2 &amp; \ldots &amp; uv_n
\end{pmatrix},\]</div>
</div></blockquote>
<p>which means that all the columns of <span class="math notranslate nohighlight">\(uv^T\)</span> are multiples of <span class="math notranslate nohighlight">\(u\)</span>. We will
see in the next section that this matrix has rank 1. In the complex
number case, the transpose <span class="math notranslate nohighlight">\(^T\)</span> is replaced by the adjoint <span class="math notranslate nohighlight">\(^*\)</span> which
is the complex conjugate of the transpose. There will be more about this
later.</p>
<section id="your-first-programming-exercises">
<h3><span class="section-number">2.1.1. </span>Your first programming exercises<a class="headerlink" href="#your-first-programming-exercises" title="Permalink to this heading">¶</a></h3>
<p>In this course, there will be programming exercises, the first one of
which is coming up right now. The aim of these programming exercises
is to gain understanding of the mathematical algorithms by expressing
them as code. The <a class="reference external" href="https://numpy.org/doc/stable/reference/index.html#module-numpy" title="(in NumPy v2.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy</span></code></a> Python package has a module called
<a class="reference external" href="https://numpy.org/doc/stable/reference/routines.linalg.html#module-numpy.linalg" title="(in NumPy v2.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.linalg</span></code></a> that contains many of these algorithms. Hence for this
course we will not use this module, just use the functions and classes
available when you import <a class="reference external" href="https://numpy.org/doc/stable/reference/index.html#module-numpy" title="(in NumPy v2.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy</span></code></a> itself. There is one exception,
which is that <code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.linalg.norm()</span></code> is quite useful, but also covers a lot
of different cases which are not very edifying to replicate. Hence,
we have included <code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.linalg.norm()</span></code> in the <a class="reference internal" href="cla_utils.html#module-cla_utils" title="cla_utils"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cla_utils</span></code></a> package as
<code class="xref py py-meth docutils literal notranslate"><span class="pre">cla_utils.norm()</span></code>, should you wish to use it.</p>
<div class="proof proof-type-exercise" id="id2">
<span id="ex-basic-matvec"></span>
    <div class="proof-title">
        <span class="proof-type">Exercise 2.1</span>
        
    </div><div class="proof-content">
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises1.basic_matvec" title="cla_utils.exercises1.basic_matvec"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises1.basic_matvec()</span></code></a> function has been left
unimplemented. To finish the function, add code so that it
computes the matrix-vector product <span class="math notranslate nohighlight">\(b=Ax\)</span> from inputs <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(x\)</span>.
In this first implementation, you should simply implement
<a class="reference internal" href="#equation-matvec">(2.1)</a> with a double nested for loop (one for the sum over <span class="math notranslate nohighlight">\(j\)</span>,
and one for the <span class="math notranslate nohighlight">\(i\)</span> elements of <span class="math notranslate nohighlight">\(b\)</span>). Run this script to test your code
(and all the exercises from this exercise set):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">py</span><span class="o">.</span><span class="n">test</span> <span class="n">test</span><span class="o">/</span><span class="n">test_exercises1</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>from the Bash Terminal. Make sure you commit your modifications
and push them to your course repository.</p>
</div></div><div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Don’t forget to activate the virtual environment before running the tests to make sure that you have access to all the necessary packages</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>The Matlab-like array features of Python are provided by <a class="reference external" href="http://www.numpy.org/">Numpy</a> for which there is a <a class="reference external" href="http://wiki.scipy.org/Tentative_NumPy_Tutorial">helpful tutorial</a>. There is also a
handy <a class="reference external" href="http://wiki.scipy.org/NumPy_for_Matlab_Users">guide for Matlab users</a>. In that context, the
code provided in this course will always use Numpy arrays, and never
Numpy matrices.</p>
</div>
<div class="proof proof-type-exercise" id="id3">
<span id="ex-column-matvec"></span>
    <div class="proof-title">
        <span class="proof-type">Exercise 2.2</span>
        
    </div><div class="proof-content">
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises1.column_matvec" title="cla_utils.exercises1.column_matvec"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises1.column_matvec()</span></code></a> function has been
left unimplemented.  To finish the function, add code so that it
computes the matrix-vector product <span class="math notranslate nohighlight">\(b=Ax\)</span> from inputs <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(x\)</span>.
This second implementation should use the column-space formulation
of matrix-vector multiplication, i.e., <span class="math notranslate nohighlight">\(b\)</span> is a weighted sum of the
columns of <span class="math notranslate nohighlight">\(A\)</span> with coefficients given by the entries in <span class="math notranslate nohighlight">\(x\)</span>.  This
should be implemented with a single for loop over the entries of
<span class="math notranslate nohighlight">\(x\)</span>. The test script <code class="docutils literal notranslate"><span class="pre">test_exercises1.py</span></code> will also test
this function.</p>
</div></div><div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It will be useful to use the Python “slice” notation, for
example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
<p>will return the 4th (since Python numbers from zero) column of <span class="math notranslate nohighlight">\(A\)</span>.
For more information, see the <a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.indexing.html">Numpy documentation on slicing.</a></p>
</div>
<div class="proof proof-type-exercise" id="id4">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.3</span>
        
    </div><div class="proof-content">
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises1.time_matvecs" title="cla_utils.exercises1.time_matvecs"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises1.time_matvecs()</span></code></a> function computes
the execution time for these two implementations for some example
matrices and compares them with the built-in Numpy matrix-vector
product. Run this function and examine the output. You should
observe that the basic implementation is much slower than the
built-in implementation. This is because built-in Numpy operations
use compiled C code that is wrapped in Python, which avoids the
overheads of run-time interpretation of the Python code and
manipulation of Python objects. Numpy is really useful for
computational linear algebra programming because it preserves the
readability and flexibility of Python (writing code that looks much
more like maths, access to object-oriented programming models)
whilst giving near-C speed if used appropriately.  You can read
more about the advantages of using Numpy <a class="reference external" href="https://numpy.org/devdocs/user/whatisnumpy.html">here</a>.  You
should also observe that the column implementation is somewhere
between the speed of the basic implementation and the built-in
implementation. This is because (if you did it correctly), each
iteration of the for loop involves adding an entire array (a
scaling of one of the columns of <span class="math notranslate nohighlight">\(A\)</span>) to another array (where <span class="math notranslate nohighlight">\(b\)</span>
is being calculated). This will also use compiled C code through
Numpy, removing some (but not all) of the Python overheads in the
basic implementation.</p>
<p>In this course, we will present algorithms in the notes that generally
do not express the way that Numpy should be used to implement them.
In these exercises you should consider the best way to make use of
Numpy built-in operations (which will often make the code more maths-like
and readable, as well as potentially faster).</p>
</div></div></section>
</section>
<section id="range-nullspace-and-rank">
<h2><span class="section-number">2.2. </span>Range, nullspace and rank<a class="headerlink" href="#range-nullspace-and-rank" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450162984" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>In this section we’ll quickly rattle through some definitions and results.</p>
<div class="proof proof-type-definition" id="id5">

    <div class="proof-title">
        <span class="proof-type">Definition 2.4</span>
        
            <span class="proof-title-name">(Range)</span>
        
    </div><div class="proof-content">
<p>The range of <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(\mbox{range}(A)\)</span>, is the set of vectors that can
be expressed as <span class="math notranslate nohighlight">\(Ax\)</span> for some <span class="math notranslate nohighlight">\(x\)</span>.</p>
</div></div><p>The next theorem follows as a result of the column space
interpretation of matrix-vector multiplication.</p>
<div class="proof proof-type-theorem" id="id6">

    <div class="proof-title">
        <span class="proof-type">Theorem 2.5</span>
        
    </div><div class="proof-content">
<p><span class="math notranslate nohighlight">\(\mbox{range}(A)\)</span> is the vector space spanned by the columns of <span class="math notranslate nohighlight">\(A\)</span>.</p>
</div></div><div class="proof proof-type-definition" id="id7">

    <div class="proof-title">
        <span class="proof-type">Definition 2.6</span>
        
            <span class="proof-title-name">(Nullspace)</span>
        
    </div><div class="proof-content">
<p>The nullspace <span class="math notranslate nohighlight">\(\mbox{null}(A)\)</span> of <span class="math notranslate nohighlight">\(A\)</span> (or kernel) is the set of
vectors <span class="math notranslate nohighlight">\(x\)</span> satisfying <span class="math notranslate nohighlight">\(Ax=0\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[\mbox{null}(A) = \{x \in \mathbb{C}^n: Ax=0\}.\]</div>
</div></div><details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450166119" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><div class="proof proof-type-definition" id="id8">

    <div class="proof-title">
        <span class="proof-type">Definition 2.7</span>
        
            <span class="proof-title-name">(Rank)</span>
        
    </div><div class="proof-content">
<p>The column rank <span class="math notranslate nohighlight">\(\mbox{rank}(A)\)</span> of <span class="math notranslate nohighlight">\(A\)</span> is the dimension of the
column space of <span class="math notranslate nohighlight">\(A\)</span>.  The row rank <span class="math notranslate nohighlight">\(\mbox{rank}(A)\)</span> of <span class="math notranslate nohighlight">\(A\)</span> is the
dimension of the row space of <span class="math notranslate nohighlight">\(A\)</span>. It can be shown that the column
rank and row rank of a matrix are equal, so we shall just refer
to the rank.</p>
</div></div><p>If</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}A = \begin{pmatrix}
a_1 &amp; a_2 &amp; \ldots &amp; a_n \\
\end{pmatrix},\end{split}\]</div>
</div></blockquote>
<p>the column space of <span class="math notranslate nohighlight">\(A\)</span> is <span class="math notranslate nohighlight">\(\mbox{span}(a_1,a_2,\ldots,a_n)\)</span>.</p>
<div class="proof proof-type-definition" id="id9">

    <div class="proof-title">
        <span class="proof-type">Definition 2.8</span>
        
    </div><div class="proof-content">
<p>An <span class="math notranslate nohighlight">\(m\times n\)</span> matrix <span class="math notranslate nohighlight">\(A\)</span> is full rank if it has maximum possible rank
i.e. rank equal to <span class="math notranslate nohighlight">\(\min(m, n)\)</span>.</p>
</div></div><p>If <span class="math notranslate nohighlight">\(m\geq n\)</span> then <span class="math notranslate nohighlight">\(A\)</span> must have <span class="math notranslate nohighlight">\(n\)</span> linearly independent columns to be
full rank. The next theorem is then a consequence of the column space
interpretation of matrix-vector multiplication.</p>
<div class="proof proof-type-theorem" id="id10">

    <div class="proof-title">
        <span class="proof-type">Theorem 2.9</span>
        
    </div><div class="proof-content">
<p>An <span class="math notranslate nohighlight">\(m\times n\)</span> matrix <span class="math notranslate nohighlight">\(A\)</span> is full rank if and only if it maps no two
distinct vectors to the same vector.</p>
</div></div><div class="proof proof-type-definition" id="id11">

    <div class="proof-title">
        <span class="proof-type">Definition 2.10</span>
        
    </div><div class="proof-content">
<p>A matrix <span class="math notranslate nohighlight">\(A\)</span> is called nonsingular, or invertible, if it is a square
matrix (<span class="math notranslate nohighlight">\(m=n\)</span>) of full rank.</p>
</div></div><div class="proof proof-type-exercise" id="id12">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.11</span>
        
    </div><div class="proof-content">
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises1.rank2" title="cla_utils.exercises1.rank2"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises1.rank2()</span></code></a> function has been left
unimplemented.  To finish the function, add code so that it
computes the rank-2 matrix <span class="math notranslate nohighlight">\(A = u_1v_1^* + u_2v_2^*\)</span> from
<span class="math notranslate nohighlight">\(u_1,u_2\in \mathbb{C}^m\)</span> and <span class="math notranslate nohighlight">\(v_1,v_2 \in \mathbb{C}^n\)</span>. As you
can see, the function needs to implement this rank-2 matrix by
first forming two matrices <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(C\)</span> from the inputs,
and then forming <span class="math notranslate nohighlight">\(A\)</span> as the product of <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(C\)</span>. The
test script <code class="docutils literal notranslate"><span class="pre">test_exercises1.py</span></code> in the <code class="docutils literal notranslate"><span class="pre">test</span></code> directory will also test this function.</p>
<p>To measure the rank of <span class="math notranslate nohighlight">\(A\)</span>, we can use the built-in rank
function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
<p>and we should find that the rank is equal to 2. Can you explain why
this should be the case (use the column space interpretation of
matrix-matrix multiplication)?</p>
</div></div></section>
<section id="invertibility-and-inverses">
<h2><span class="section-number">2.3. </span>Invertibility and inverses<a class="headerlink" href="#invertibility-and-inverses" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450171203" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>This means that an invertible matrix has columns that form a basis for
<span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span>. Given the canonical basis vectors defined by</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\begin{split}e_j = \begin{pmatrix}
0 \\
\ldots \\
0 \\
1 \\
0 \\
\ldots \\
0 \\
\end{pmatrix},\end{split}\]</div>
</div></blockquote>
<p>i.e. <span class="math notranslate nohighlight">\(e_j\)</span> has all entries zero except for the jth entry which is 1, we can
write</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[e_j = \sum_{k=1}^m z_{jk} a_k, \quad 1\leq j \leq m.\]</div>
</div></blockquote>
<p>In other words,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}I =
\begin{pmatrix}
e_1 &amp; e_2 &amp; \ldots &amp; e_m
\end{pmatrix}\\= ZA.\end{aligned}\end{align} \]</div>
</div></blockquote>
<dl class="simple">
<dt>We call <span class="math notranslate nohighlight">\(Z\)</span> a (left) inverse of <span class="math notranslate nohighlight">\(A\)</span>. It can be shown that <span class="math notranslate nohighlight">\(Z\)</span> is the</dt><dd><p>unique left inverse of <span class="math notranslate nohighlight">\(A\)</span>, and that <span class="math notranslate nohighlight">\(Z\)</span> is also the unique right
inverse of <span class="math notranslate nohighlight">\(A\)</span>, satisfying <span class="math notranslate nohighlight">\(I = AZ\)</span>. We write <span class="math notranslate nohighlight">\(Z=A^{-1}\)</span>.</p>
</dd>
</dl>
<p>The first four parts of the next theorem are a consequence of what
we have so far, and we shall quote the fifth and sixth (see a linear algebra
course).</p>
<div class="proof proof-type-theorem" id="id13">

    <div class="proof-title">
        <span class="proof-type">Theorem 2.12</span>
        
    </div><div class="proof-content">
<p>Let <span class="math notranslate nohighlight">\(A \in \mathbb{C}^{m\times m}\)</span>. Then the following are equivalent.</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(A\)</span> has an inverse.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mbox{rank}(A)=m\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mbox{range}(A)=\mathbb{C}^m\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mbox{null}(A)=\{0\}\)</span>.</p></li>
<li><p>0 is not an eigenvalue of <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>The determinant <span class="math notranslate nohighlight">\(\det(A)\neq 0\)</span>.</p></li>
</ol>
</div></div><details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450172407" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>Finding the inverse of a matrix can be seen as a change of basis. Considering
the equation <span class="math notranslate nohighlight">\(Ax= b\)</span>, we have <span class="math notranslate nohighlight">\(x = A^{-1}b\)</span> for invertible <span class="math notranslate nohighlight">\(A\)</span>. We have
seen already that <span class="math notranslate nohighlight">\(b\)</span> can be written as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[b = \sum_{j=1}^m x_j a_j.\]</div>
</div></blockquote>
<p>Since the columns of <span class="math notranslate nohighlight">\(A\)</span> span <span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span>, the entries of <span class="math notranslate nohighlight">\(x\)</span> thus
provide the unique expansion of <span class="math notranslate nohighlight">\(b\)</span> in the columns of <span class="math notranslate nohighlight">\(A\)</span> which form a
basis.  Hence, whilst the entries of <span class="math notranslate nohighlight">\(b\)</span> give basis coefficients for
<span class="math notranslate nohighlight">\(b\)</span> in the canonical basis <span class="math notranslate nohighlight">\((e_1,e_2,\ldots,e_m)\)</span>, the entries of <span class="math notranslate nohighlight">\(x\)</span>
give basis coefficients for <span class="math notranslate nohighlight">\(b\)</span> in the basis given by the columns of <span class="math notranslate nohighlight">\(A\)</span>.</p>
<div class="proof proof-type-exercise" id="id14">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.13</span>
        
    </div><div class="proof-content">
<p>For matrices of the form, <span class="math notranslate nohighlight">\(A = I + uv^*\)</span>, where <span class="math notranslate nohighlight">\(I\)</span> is the <span class="math notranslate nohighlight">\(m\times
m\)</span> identity matrix, and <span class="math notranslate nohighlight">\(u,v \in \mathbb{C}^m\)</span>, show that whenever
<span class="math notranslate nohighlight">\(A\)</span> is invertible, the inverse is of the form <span class="math notranslate nohighlight">\(A^{-1} = I + \alpha uv^*\)</span>
where <span class="math notranslate nohighlight">\(\alpha \in \mathbb{C}\)</span>, and calculate the form of <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises1.rank1pert_inv" title="cla_utils.exercises1.rank1pert_inv"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises1.rank1pert_inv()</span></code></a> function has been
left unimplemented.  To finish the function, add code so that it
computes <span class="math notranslate nohighlight">\(A^{-1}\)</span> using your formula (and not any built-in matrix
inversion routines). The test script <code class="docutils literal notranslate"><span class="pre">test_exercises1.py</span></code> in the
<code class="docutils literal notranslate"><span class="pre">test</span></code> directory will also test this function.</p>
<p>Add a function to <a class="reference internal" href="cla_utils.html#module-cla_utils.exercises1" title="cla_utils.exercises1"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cla_utils.exercises1</span></code></a> that measures the
time to compute the inverse of <span class="math notranslate nohighlight">\(A\)</span> for an input matrix of size 400,
and compare with the time to compute the inverse of <span class="math notranslate nohighlight">\(A\)</span> using the built-in
inverse:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
<p>What do you observe? Why do you think this is? We will examine the
cost of general purpose matrix inversion algorithms later.</p>
</div></div></section>
<section id="adjoints-and-hermitian-matrices">
<h2><span class="section-number">2.4. </span>Adjoints and Hermitian matrices<a class="headerlink" href="#adjoints-and-hermitian-matrices" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450173092" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><div class="proof proof-type-definition" id="id15">

    <div class="proof-title">
        <span class="proof-type">Definition 2.14</span>
        
            <span class="proof-title-name">(Adjoint)</span>
        
    </div><div class="proof-content">
<p>The adjoint (or Hermitian conjugate) of <span class="math notranslate nohighlight">\(A\in \mathbb{C}^{m\times n}\)</span>
is a matrix <span class="math notranslate nohighlight">\(A^* \in \mathbb{C}^{n\times m}\)</span> (sometimes written
<span class="math notranslate nohighlight">\(A^\dagger\)</span> or <span class="math notranslate nohighlight">\(A'\)</span>), with</p>
<div class="math notranslate nohighlight">
\[a^*_{ij} = \bar{a_{ji}},\]</div>
<p>where the bar denotes the complex conjugate of a complex number. If
<span class="math notranslate nohighlight">\(A^* = A\)</span> then we say that <span class="math notranslate nohighlight">\(A\)</span> is Hermitian.</p>
<p>For real matrices, <span class="math notranslate nohighlight">\(A^*=A^T\)</span>. If <span class="math notranslate nohighlight">\(A=A^T\)</span>, then we say that the matrix
is symmetric.</p>
</div></div><p>The following identity is very important when dealing with adjoints.</p>
<div class="proof proof-type-theorem" id="id16">

    <div class="proof-title">
        <span class="proof-type">Theorem 2.15</span>
        
    </div><div class="proof-content">
<p>For matrices <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(B\)</span> with compatible dimensions (so that they can
be multiplied),</p>
<div class="math notranslate nohighlight">
\[(AB)^* = B^*A^*.\]</div>
</div></div><div class="proof proof-type-exercise" id="id17">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.16</span>
        
    </div><div class="proof-content">
<p>(This is an advanced exercise if the other exercises are complete.
If you are behind on the exercises please skip this one.)</p>
<p>Consider a matrix <span class="math notranslate nohighlight">\(A=B + iC\)</span> where <span class="math notranslate nohighlight">\(B,C\in\mathbb{R}^{m\times m}\)</span>
and <span class="math notranslate nohighlight">\(A\)</span> is Hermitian. Show that <span class="math notranslate nohighlight">\(B=B^T\)</span> and <span class="math notranslate nohighlight">\(C=-C^T\)</span>. To save
memory, instead of storing values of <span class="math notranslate nohighlight">\(A\)</span> (<span class="math notranslate nohighlight">\(m\times m\)</span> complex
numbers to store), consider equivalently storing a real-valued
<span class="math notranslate nohighlight">\(m\times m\)</span> array <span class="math notranslate nohighlight">\(\hat{A}\)</span> with <span class="math notranslate nohighlight">\(\hat{A}_{ij}=B_{ij}\)</span> for <span class="math notranslate nohighlight">\(i\geq j\)</span>
and <span class="math notranslate nohighlight">\(\hat{A}_{ij}=C_{ij}\)</span> for <span class="math notranslate nohighlight">\(i&lt;j\)</span>.</p>
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises1.ABiC" title="cla_utils.exercises1.ABiC"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises1.ABiC()</span></code></a> function has been left
unimplemented. It should implement matrix vector multiplication
<span class="math notranslate nohighlight">\(z=Ax\)</span>, returning the real and imaginary parts of <span class="math notranslate nohighlight">\(z\)</span>, given the
real and imaginary parts of <span class="math notranslate nohighlight">\(x\)</span> as inputs, and given the real array
<span class="math notranslate nohighlight">\(\hat{A}\)</span> as above. You should implement the multiplication using
real arithmetic only, with just one loop over the entries of <span class="math notranslate nohighlight">\(x\)</span>,
using the column space interpretation of matrix-vector
multiplication. The test script <code class="docutils literal notranslate"><span class="pre">test_exercises1.py</span></code> in the
<code class="docutils literal notranslate"><span class="pre">test</span></code> directory will also test this function.</p>
</div></div><div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can use the Python “slice” notation, to assign into a slice
of an array, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
<p>will copy the 4th and 5th entries of <span class="math notranslate nohighlight">\(y\)</span> (Python numbers from zero,
and the upper limit of the slice is the first index value not to
use.  For more information, see the <a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.indexing.html">Numpy documentation on
slicing.</a></p>
</div>
</section>
<section id="inner-products-and-orthogonality">
<h2><span class="section-number">2.5. </span>Inner products and orthogonality<a class="headerlink" href="#inner-products-and-orthogonality" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450172520" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>The inner product is a critical tool in computational linear algebra.</p>
<div class="proof proof-type-definition" id="id18">

    <div class="proof-title">
        <span class="proof-type">Definition 2.17</span>
        
            <span class="proof-title-name">(Inner product)</span>
        
    </div><div class="proof-content">
<p>Let <span class="math notranslate nohighlight">\(x,y\in \mathbb{C}^m\)</span>. Then the inner product of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> is</p>
<div class="math notranslate nohighlight">
\[x^*y = \sum_{i=1}^m \bar{x}_iy_i.\]</div>
</div></div><p>We will frequently use the natural norm derived from the inner product
to define size of vectors.</p>
<div class="proof proof-type-definition" id="id19">

    <div class="proof-title">
        <span class="proof-type">Definition 2.18</span>
        
            <span class="proof-title-name">(2-Norm)</span>
        
    </div><div class="proof-content">
<p>Let <span class="math notranslate nohighlight">\(x\in \mathbb{C}^m\)</span>. Then the 2-norm of <span class="math notranslate nohighlight">\(x\)</span> is</p>
<div class="math notranslate nohighlight">
\[\|x\| = \sqrt{\sum_{i=1}^m |x_i|^2} = \sqrt{x^*x}.\]</div>
</div></div><p>Orthogonality will emerge as an early key concept in this course.</p>
<div class="proof proof-type-definition" id="id20">

    <div class="proof-title">
        <span class="proof-type">Definition 2.19</span>
        
            <span class="proof-title-name">(Orthogonal vectors)</span>
        
    </div><div class="proof-content">
<p>Let <span class="math notranslate nohighlight">\(x,y\in \mathbb{C}^m\)</span>. The two vectors are orthogonal if
<span class="math notranslate nohighlight">\(x^*y=0\)</span>.</p>
<p>Similarly, let <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span> be two sets of vectors. The two sets
are orthogonal if</p>
<div class="math notranslate nohighlight">
\[x^*y = 0,\quad \forall x\in X, \, y\in Y.\]</div>
<p>A set <span class="math notranslate nohighlight">\(S\)</span> of vectors is itself orthogonal if</p>
<div class="math notranslate nohighlight">
\[x^*y = 0,\quad\forall x,y \in S.\]</div>
<p>We say that <span class="math notranslate nohighlight">\(S\)</span> is orthonormal if we also have <span class="math notranslate nohighlight">\(\|x\|=1\)</span>
for all <span class="math notranslate nohighlight">\(x\in S\)</span>.</p>
</div></div></section>
<section id="orthogonal-components-of-a-vector">
<h2><span class="section-number">2.6. </span>Orthogonal components of a vector<a class="headerlink" href="#orthogonal-components-of-a-vector" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450184086" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>Let <span class="math notranslate nohighlight">\(S=\{q_1,q_2,\ldots,q_n\}\)</span> be an orthonormal set of vectors in
<span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span>, and take another arbitrary vector <span class="math notranslate nohighlight">\(v\in \mathbb{C}^m\)</span>.
Now take</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[r = v - (q_1^*v)q_1 - (q_2^*v)q_2 - \ldots - (q_n^*v)q_n.\]</div>
</div></blockquote>
<p>Then, we can check that <span class="math notranslate nohighlight">\(r\)</span> is orthogonal to <span class="math notranslate nohighlight">\(S\)</span>, by calculating
for each <span class="math notranslate nohighlight">\(1\leq i \leq n\)</span>,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}q^*_ir = q_i^*v - (q_1^*v)(q_i^*q_1) - \ldots - (q_n^*v)(q_i^*q_n)\\= q_i^*v - q_i^*v = 0,\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>since <span class="math notranslate nohighlight">\(q_i^*q_j=0\)</span> if <span class="math notranslate nohighlight">\(i\neq j\)</span>, and 1 if <span class="math notranslate nohighlight">\(i=j\)</span>.
Thus,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[v = r + \sum_{i=1}^n (q_i^*v)q_i
= r + \sum_{i=1}^n \underbrace{(q_i q_i^*)}_{\mbox{rank-1 matrix}}v.\]</div>
</div></blockquote>
<p>If <span class="math notranslate nohighlight">\(S\)</span> is a basis for <span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span>, then <span class="math notranslate nohighlight">\(n=m\)</span> and <span class="math notranslate nohighlight">\(r=0\)</span>, and we have</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[v = \sum_{i=1}^m (q_i q_i^*)v.\]</div>
</div></blockquote>
<div class="proof proof-type-exercise" id="id21">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.20</span>
        
    </div><div class="proof-content">
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises2.orthog_cpts" title="cla_utils.exercises2.orthog_cpts"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises2.orthog_cpts()</span></code></a> function has been left
unimplemented. It should implement the above computation, returning
<span class="math notranslate nohighlight">\(r\)</span> and the coefficients of the component of <span class="math notranslate nohighlight">\(v\)</span> in each
orthonormal direction. The test script <code class="docutils literal notranslate"><span class="pre">test_exercises2.py</span></code> in
the <code class="docutils literal notranslate"><span class="pre">test</span></code> directory will test this function.</p>
</div></div></section>
<section id="unitary-matrices">
<h2><span class="section-number">2.7. </span>Unitary matrices<a class="headerlink" href="#unitary-matrices" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450184373" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><div class="proof proof-type-definition" id="id22">

    <div class="proof-title">
        <span class="proof-type">Definition 2.21</span>
        
            <span class="proof-title-name">(Unitary matrices)</span>
        
    </div><div class="proof-content">
<p>A matrix <span class="math notranslate nohighlight">\(Q\in \mathbb{C}^{m\times m}\)</span> is unitary if <span class="math notranslate nohighlight">\(Q^* =Q^{-1}\)</span>.</p>
<p>For real matrices, a matrix <span class="math notranslate nohighlight">\(Q\)</span>  is orthogonal if <span class="math notranslate nohighlight">\(Q^T=Q^{-1}\)</span>.</p>
</div></div><div class="proof proof-type-theorem" id="id23">

    <div class="proof-title">
        <span class="proof-type">Theorem 2.22</span>
        
    </div><div class="proof-content">
<p>The columns of a unitary matrix <span class="math notranslate nohighlight">\(Q\)</span> are orthonormal.</p>
</div></div><div class="proof proof-type-proof">

    <div class="proof-title">
        <span class="proof-type">Proof </span>
        
    </div><div class="proof-content">
<p>We have <span class="math notranslate nohighlight">\(I = Q^*Q\)</span>. Then using the column space interpretation
of matrix-matrix multiplication,</p>
<div class="math notranslate nohighlight">
\[e_j = Q^*q_j,\]</div>
<p>where <span class="math notranslate nohighlight">\(q_j\)</span> is the jth column of <span class="math notranslate nohighlight">\(Q\)</span>. Taking row i of <span class="math notranslate nohighlight">\(e_j\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\delta_{ij} = q_i^*q_j, \mbox{ where }
\delta_{ij} = \left\{
\begin{array}{ccc}
1 &amp; \mbox{if} &amp; i=j, \\
0 &amp; \mbox{otherwise} &amp; \\
\end{array}\right. .\end{split}\]</div>
</div></div><p>Extending a theme from earlier, we can interpret <span class="math notranslate nohighlight">\(Q^*=Q^{-1}\)</span> as
representing a change of orthogonal basis. If <span class="math notranslate nohighlight">\(Qx = b\)</span>, then
<span class="math notranslate nohighlight">\(x=Q^*b\)</span> contains the coefficients of <span class="math notranslate nohighlight">\(b\)</span> expanded in the basis
given by the orthonormal columns of <span class="math notranslate nohighlight">\(Q\)</span>.</p>
<div class="proof proof-type-exercise" id="id24">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.23</span>
        
    </div><div class="proof-content">
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises2.solveQ()</span></code> function has been left
unimplemented. Given a square unitary matrix <span class="math notranslate nohighlight">\(Q\)</span> and a vector <span class="math notranslate nohighlight">\(b\)</span>
it should solve <span class="math notranslate nohighlight">\(Qx=b\)</span> using information above (it is not expected
to work when <span class="math notranslate nohighlight">\(Q\)</span> is not unitary or square). The test script
<code class="docutils literal notranslate"><span class="pre">test_exercises2.py</span></code> in the <code class="docutils literal notranslate"><span class="pre">test</span></code> directory will test this
function.</p>
<p>Add a function to <a class="reference internal" href="cla_utils.html#module-cla_utils.exercises2" title="cla_utils.exercises2"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cla_utils.exercises2</span></code></a> that measures the
time to solve <span class="math notranslate nohighlight">\(Qx=b\)</span> using <code class="docutils literal notranslate"><span class="pre">solveQ</span></code> for an input matrix of sizes 100,
200, 400,
and compare with the times to solve the equation using the general purpose
solve (which uses LU factorisation, which we will discuss later):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>What did you expect and was it observed?</p>
<p>A quick way to get an orthogonal matrix is to take a general matrix $A$
and find the QR factorisation, which we will cover in the next section.</p>
<blockquote>
<div><p>Q, R = numpy.linalg.qr(A)</p>
</div></blockquote>
<p>returns two matrices, of which <span class="math notranslate nohighlight">\(Q\)</span> is orthogonal.</p>
</div></div></section>
<section id="vector-norms">
<h2><span class="section-number">2.8. </span>Vector norms<a class="headerlink" href="#vector-norms" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450184674" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>Various vector norms are useful to measure the size of a vector.
In computational linear algebra we need them for quantifying errors
etc.</p>
<div class="proof proof-type-definition" id="id25">

    <div class="proof-title">
        <span class="proof-type">Definition 2.24</span>
        
            <span class="proof-title-name">(Norms)</span>
        
    </div><div class="proof-content">
<p>A norm is a function <span class="math notranslate nohighlight">\(\|\cdot\|:\mathbb{C}^m \to \mathbb{R}\)</span>, such that</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\|x\|\geq 0\)</span>, and <span class="math notranslate nohighlight">\(\|x\|=0\implies x =0.\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\|x+y\| \leq \|x\| + \|y\|\)</span> (triangle inequality).</p></li>
<li><p><span class="math notranslate nohighlight">\(\|\alpha x\| = |\alpha|\|x\|\)</span> for all <span class="math notranslate nohighlight">\(x \in \mathbb{C}^m\)</span>
and <span class="math notranslate nohighlight">\(\alpha \in \mathbb{C}\)</span>.</p></li>
</ol>
</div></div><p>We have already seen the 2-norm, or Euclidean norm, which is part of a
larger class of norms called p-norms, with</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\|x\|_p = \left(\sum_{i=1}^m |x_i|^p\right)^{1/p}, \quad\]</div>
</div></blockquote>
<p>for real <span class="math notranslate nohighlight">\(p&gt;0\)</span>. We will also consider weighted norms</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\|x\|_{W,p} = \|Wx \|_p,\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(W\)</span> is a matrix.</p>
</section>
<section id="projectors-and-projections">
<h2><span class="section-number">2.9. </span>Projectors and projections<a class="headerlink" href="#projectors-and-projections" title="Permalink to this heading">¶</a></h2>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450185110" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><div class="proof proof-type-definition" id="id26">

    <div class="proof-title">
        <span class="proof-type">Definition 2.25</span>
        
            <span class="proof-title-name">(Projector)</span>
        
    </div><div class="proof-content">
<p>A projector <span class="math notranslate nohighlight">\(P\)</span> is a square matrix that satisfies <span class="math notranslate nohighlight">\(P^2=P\)</span>.</p>
</div></div><p>If <span class="math notranslate nohighlight">\(v \in \mbox{range}(P)\)</span>, then there exists <span class="math notranslate nohighlight">\(x\)</span> such that
<span class="math notranslate nohighlight">\(Px = v\)</span>. Then,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[Pv = P(Px) = P^2x = Px = v,\]</div>
</div></blockquote>
<p>and hence multiplying by <span class="math notranslate nohighlight">\(P\)</span> does not change <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p>Now suppose that <span class="math notranslate nohighlight">\(Pv \neq v\)</span> (so that <span class="math notranslate nohighlight">\(v\notin \mbox{range}(P)\)</span>).
Then,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[P(Pv - v) = P^2v - Pv = Pv - Pv = 0,\]</div>
</div></blockquote>
<p>which means that <span class="math notranslate nohighlight">\(Pv-v\)</span> is the nullspace of <span class="math notranslate nohighlight">\(P\)</span>. We have</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[Pv -v = -(I-P)v.\]</div>
</div></blockquote>
<div class="proof proof-type-definition" id="id27">

    <div class="proof-title">
        <span class="proof-type">Definition 2.26</span>
        
            <span class="proof-title-name">(Complementary projector)</span>
        
    </div><div class="proof-content">
<p>Let <span class="math notranslate nohighlight">\(P\)</span> be a projector. Then we call <span class="math notranslate nohighlight">\(I-P\)</span> the complementary projector.</p>
</div></div><p>To see that <span class="math notranslate nohighlight">\(I-P\)</span> is also a projector, we just calculate,</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[(I-P)^2 = I^2 - 2P + P^2 = I - 2P + P = I - P.\]</div>
</div></blockquote>
<p>If <span class="math notranslate nohighlight">\(Pu=0\)</span>, then <span class="math notranslate nohighlight">\((I-P)u = u\)</span>.</p>
<p>In other words, the nullspace
of <span class="math notranslate nohighlight">\(P\)</span> is contained in the range of <span class="math notranslate nohighlight">\(I-P\)</span>.</p>
<p>On the other hand, if <span class="math notranslate nohighlight">\(v\)</span> is in the range of <span class="math notranslate nohighlight">\(I-P\)</span>,  then
there exists some <span class="math notranslate nohighlight">\(w\)</span> such that</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[v = (I-P)w = w - Pw.\]</div>
</div></blockquote>
<p>We have</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[Pv = P(w-Pw) = Pw - P^2w = Pw - Pw = 0.\]</div>
</div></blockquote>
<p>Hence, the range of <span class="math notranslate nohighlight">\(I-P\)</span> is contained in the nullspace of <span class="math notranslate nohighlight">\(P\)</span>.
Combining these two results we see that the range of <span class="math notranslate nohighlight">\(I-P\)</span>
is equal to the nullspace of <span class="math notranslate nohighlight">\(P\)</span>. Since <span class="math notranslate nohighlight">\(P\)</span> is the complementary
projector to <span class="math notranslate nohighlight">\(I-P\)</span>, we can repeat the same argument to show
that the range of <span class="math notranslate nohighlight">\(P\)</span> is equal to the nullspace of <span class="math notranslate nohighlight">\(I-P\)</span>.</p>
<p>We see that a projector <span class="math notranslate nohighlight">\(P\)</span> separates <span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span> into two
subspaces, the nullspace of <span class="math notranslate nohighlight">\(P\)</span> and the range of <span class="math notranslate nohighlight">\(P\)</span>. In fact the
converse is also true: given two subspaces <span class="math notranslate nohighlight">\(S_1\)</span> and <span class="math notranslate nohighlight">\(S_2\)</span>
of <span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span> with <span class="math notranslate nohighlight">\(S_1 \cap S_2 = \{0\}\)</span>, then there
exists a projector <span class="math notranslate nohighlight">\(P\)</span> whose range is <span class="math notranslate nohighlight">\(S_1\)</span> and whose nullspace
is <span class="math notranslate nohighlight">\(S_2\)</span>.</p>
<details>
<summary>
Supplementary video</summary><div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://player.vimeo.com/video/450185494" style="border: 0; height: 345px; width: 560px">
</iframe></div></details><p>Now we introduce orthogonality into the concept of projectors.</p>
<div class="proof proof-type-definition" id="id28">

    <div class="proof-title">
        <span class="proof-type">Definition 2.27</span>
        
            <span class="proof-title-name">(Orthogonal projector)</span>
        
    </div><div class="proof-content">
<p><span class="math notranslate nohighlight">\(P\)</span> is an orthogonal projector if</p>
<div class="math notranslate nohighlight">
\[(Pv)^*(Pv-v) = 0, \, \forall v \in \mathbb{C}^m.\]</div>
</div></div><p>In this case, <span class="math notranslate nohighlight">\(P\)</span> separates the space into two orthogonal subspaces.</p>
</section>
<section id="constructing-orthogonal-projectors-from-sets-of-orthonormal-vectors">
<h2><span class="section-number">2.10. </span>Constructing orthogonal projectors from sets of orthonormal vectors<a class="headerlink" href="#constructing-orthogonal-projectors-from-sets-of-orthonormal-vectors" title="Permalink to this heading">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(\{q_1,\ldots,q_n\}\)</span> be an orthonormal set of vectors in
<span class="math notranslate nohighlight">\(\mathbb{C}^m\)</span>. We write</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{Q} = \begin{pmatrix}
q_1 &amp; q_2 &amp; \ldots &amp; q_n \\
\end{pmatrix}.\end{split}\]</div>
<p>Previously we showed that for any <span class="math notranslate nohighlight">\(v\in \mathbb{C}^m\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[v = \underbrace{r}_{\mbox{Orthogonal to column space of }\hat{Q}} +
\underbrace{\sum_{i=1}^n (q_iq^*_i)v}_{\mbox{in the column space of }\hat{Q}}.\]</div>
<p>Hence, the map</p>
<div class="math notranslate nohighlight">
\[v \mapsto Pv = \underbrace{\sum_{i=1}^n (q_iq^*_i)}_{=P}v,\]</div>
<p>is an orthogonal projector. In fact, <span class="math notranslate nohighlight">\(P\)</span> has very simple form.</p>
<div class="proof proof-type-theorem" id="id29">
<span id="orthogonal-projector"></span>
    <div class="proof-title">
        <span class="proof-type">Theorem 2.28</span>
        
    </div><div class="proof-content">
<p>The orthogonal projector <span class="math notranslate nohighlight">\(P\)</span> takes the form</p>
<div class="math notranslate nohighlight">
\[P = \hat{Q}\hat{Q}^*.\]</div>
</div></div><div class="proof proof-type-proof">

    <div class="proof-title">
        <span class="proof-type">Proof </span>
        
    </div><div class="proof-content">
<p>From the change of basis interpretation of multiplication by
<span class="math notranslate nohighlight">\(\hat{Q}^*\)</span>, the entries in <span class="math notranslate nohighlight">\(\hat{Q}^*v\)</span> gives coefficients of the
projection of <span class="math notranslate nohighlight">\(v\)</span> onto the column space of <span class="math notranslate nohighlight">\(\hat{Q}\)</span> when expanded
using the columns as a basis. Then, multiplication by <span class="math notranslate nohighlight">\(\hat{Q}\)</span>
gives the projection of <span class="math notranslate nohighlight">\(v\)</span> expanded again in the canonical basis.
Hence, multiplication by <span class="math notranslate nohighlight">\(\hat{Q}\hat{Q}^*\)</span> gives exactly the same
result as multiplication by the formula for <span class="math notranslate nohighlight">\(P\)</span> above.</p>
</div></div><p>This means that <span class="math notranslate nohighlight">\(\hat{Q}\hat{Q}^*\)</span> is an orthogonal projection onto
the range of <span class="math notranslate nohighlight">\(\hat{Q}\)</span>. The complementary projector is <span class="math notranslate nohighlight">\(P_{\perp} =
I - \hat{Q}\hat{Q}^*\)</span> is an orthogonal projection onto the nullspace
of <span class="math notranslate nohighlight">\(\hat{Q}\)</span>.</p>
<p>An important special case is when <span class="math notranslate nohighlight">\(\hat{Q}\)</span> has just one column,
and then</p>
<div class="math notranslate nohighlight">
\[P = q_1q_1^*, \, P_{\perp}=I - q_1q_1^*.\]</div>
<p>We notice that <span class="math notranslate nohighlight">\(P^* = (\hat{Q}\hat{Q}^*) = \hat{Q}\hat{Q}^* = P\)</span>.
In fact the following is true.</p>
<div class="proof proof-type-theorem" id="id30">

    <div class="proof-title">
        <span class="proof-type">Theorem 2.29</span>
        
    </div><div class="proof-content">
<p><span class="math notranslate nohighlight">\(P=P^*\)</span> if and only if <span class="math notranslate nohighlight">\(\hat{Q}\)</span> is orthogonal.</p>
</div></div><div class="proof proof-type-exercise" id="id31">

    <div class="proof-title">
        <span class="proof-type">Exercise 2.30</span>
        
    </div><div class="proof-content">
<p>The <a class="reference internal" href="cla_utils.html#cla_utils.exercises2.orthog_proj" title="cla_utils.exercises2.orthog_proj"><code class="xref py py-func docutils literal notranslate"><span class="pre">cla_utils.exercises2.orthog_proj()</span></code></a> function has been left
unimplemented. Given an orthonormal set <span class="math notranslate nohighlight">\(q_1,q_2,\ldots,q_n\)</span>, it
should provide the orthogonal projector <span class="math notranslate nohighlight">\(P\)</span>. The test script
<code class="docutils literal notranslate"><span class="pre">test_exercises2.py</span></code> in the <code class="docutils literal notranslate"><span class="pre">test</span></code> directory will also test
this function.</p>
</div></div></section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020-2023, Colin J. Cotter.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.0.1.
    </div>
  </body>
</html>